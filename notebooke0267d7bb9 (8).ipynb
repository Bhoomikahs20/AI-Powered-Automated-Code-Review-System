{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11223149,"sourceType":"datasetVersion","datasetId":7009227}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset (assuming it's a CSV file)\ndf = pd.read_csv('/kaggle/input/optmized/optimized_code_dataset.csv')\n\n# Filter for Python Defect Detection\npython_dd = df[(df['language'] == 'Python') & (df['category'] == 'Defect Detection')]\n\n# Extract code snippets and labels\ncodes = python_dd['input'].tolist()\nlabels = python_dd['label'].apply(lambda x: 1 if x == 'Buggy' else 0).tolist()\n\n# Split into training and validation sets (80% train, 20% validation)\ntrain_codes, val_codes, train_labels, val_labels = train_test_split(\n    codes, labels, test_size=0.2, random_state=42\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:25:35.226673Z","iopub.execute_input":"2025-07-22T08:25:35.226952Z","iopub.status.idle":"2025-07-22T08:25:37.206561Z","shell.execute_reply.started":"2025-07-22T08:25:35.226923Z","shell.execute_reply":"2025-07-22T08:25:37.205560Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Load CodeBERT tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n\n# Tokenize the code snippets\ntrain_encodings = tokenizer(train_codes, truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_codes, truncation=True, padding=True, max_length=512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:25:37.207576Z","iopub.execute_input":"2025-07-22T08:25:37.207876Z","iopub.status.idle":"2025-07-22T08:25:48.194788Z","shell.execute_reply.started":"2025-07-22T08:25:37.207810Z","shell.execute_reply":"2025-07-22T08:25:48.193704Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faae4854319e439b9fd5ef8870489465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc8ac268e384226b484b152ae66d603"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f360046ef014e3a9aadd69c4f61ae26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de8c96d812604a0398e1431e2c59562e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd81aca7d0df4313965bf8c290ae5e49"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch\n\nclass CodeDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = CodeDataset(train_encodings, train_labels)\nval_dataset = CodeDataset(val_encodings, val_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:32:59.333215Z","iopub.execute_input":"2025-07-22T08:32:59.333580Z","iopub.status.idle":"2025-07-22T08:32:59.339166Z","shell.execute_reply.started":"2025-07-22T08:32:59.333548Z","shell.execute_reply":"2025-07-22T08:32:59.338206Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_API_KEY\"] = \"4690372435c819ac0ecb55ce65563f61980d8b0d\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:25:48.203562Z","iopub.execute_input":"2025-07-22T08:25:48.203778Z","iopub.status.idle":"2025-07-22T08:25:48.220041Z","shell.execute_reply.started":"2025-07-22T08:25:48.203759Z","shell.execute_reply":"2025-07-22T08:25:48.219107Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install wandb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:25:48.221720Z","iopub.execute_input":"2025-07-22T08:25:48.222011Z","iopub.status.idle":"2025-07-22T08:25:52.513162Z","shell.execute_reply.started":"2025-07-22T08:25:48.221982Z","shell.execute_reply":"2025-07-22T08:25:52.512225Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n\n# Load the CodeBERT model\nmodel = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=2)\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    report_to=\"none\",\n)\n\n# Initialize the trainer with the actual model and datasets\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,  # Replace with your actual training dataset\n    eval_dataset=val_dataset,     # Replace with your actual evaluation dataset\n)\n\n# Train the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:33:08.539416Z","iopub.execute_input":"2025-07-22T08:33:08.539820Z","iopub.status.idle":"2025-07-22T08:33:15.033060Z","shell.execute_reply.started":"2025-07-22T08:33:08.539784Z","shell.execute_reply":"2025-07-22T08:33:15.032179Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3/3 00:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3, training_loss=0.7403988838195801, metrics={'train_runtime': 2.6448, 'train_samples_per_second': 2.269, 'train_steps_per_second': 1.134, 'total_flos': 33916659480.0, 'train_loss': 0.7403988838195801, 'epoch': 3.0})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Save the full model (config + weights)\ntrainer.save_model(\"codebert_saved_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:33:18.794752Z","iopub.execute_input":"2025-07-22T08:33:18.795177Z","iopub.status.idle":"2025-07-22T08:33:20.109574Z","shell.execute_reply.started":"2025-07-22T08:33:18.795139Z","shell.execute_reply":"2025-07-22T08:33:20.108628Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Load GraphCodeBERT tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\", num_labels=2)\n\n# Tokenize data (re-run tokenization with GraphCodeBERT tokenizer)\ntrain_encodings = tokenizer(train_codes, truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_codes, truncation=True, padding=True, max_length=512)\ntrain_dataset = CodeDataset(train_encodings, train_labels)\nval_dataset = CodeDataset(val_encodings, val_labels)\n\n# Update training arguments\ntraining_args.output_dir = './results_graphcodebert'\ntraining_args.logging_dir = './logs_graphcodebert'\n\n# Initialize and train\ntrainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset)\ntrainer.train()\ngraphcodebert_metrics = trainer.evaluate()\nprint(\"GraphCodeBERT Metrics:\", graphcodebert_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:33:21.416332Z","iopub.execute_input":"2025-07-22T08:33:21.416676Z","iopub.status.idle":"2025-07-22T08:33:32.914846Z","shell.execute_reply.started":"2025-07-22T08:33:21.416647Z","shell.execute_reply":"2025-07-22T08:33:32.913999Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3/3 00:06, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"GraphCodeBERT Metrics: {'eval_loss': 0.6292399764060974, 'eval_runtime': 0.0143, 'eval_samples_per_second': 69.712, 'eval_steps_per_second': 69.712, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    acc = accuracy_score(labels, preds)\n    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:29:08.816795Z","iopub.execute_input":"2025-07-22T08:29:08.817132Z","iopub.status.idle":"2025-07-22T08:29:08.829851Z","shell.execute_reply.started":"2025-07-22T08:29:08.817096Z","shell.execute_reply":"2025-07-22T08:29:08.829003Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nimport torch\nfrom torch.utils.data import Dataset\n\n# Define a custom dataset class\nclass CodeDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"Salesforce/codet5-base\", num_labels=2)\n\n# Sample data (Replace with actual dataset)\ntrain_codes = [\"def foo():\\n    return 42\", \"def bar():\\n    return 'hello'\"]\nval_codes = [\"def baz():\\n    return 3.14\"]\ntrain_labels = [0, 1]  # Binary labels\nval_labels = [1]\n\n# Tokenize datasets\ntrain_encodings = tokenizer(train_codes, truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_codes, truncation=True, padding=True, max_length=512)\n\n# Create dataset objects\ntrain_dataset = CodeDataset(train_encodings, train_labels)\nval_dataset = CodeDataset(val_encodings, val_labels)\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results_codet5\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    logging_dir=\"./logs_codet5\",\n    logging_steps=50,\n    report_to=\"none\"\n)\n\n# Initialize trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset\n)\n\n# Train and evaluate\ntrainer.train()\ncodet5_metrics = trainer.evaluate()\nprint(\"CodeT5 Metrics:\", codet5_metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:29:08.830905Z","iopub.execute_input":"2025-07-22T08:29:08.831183Z","iopub.status.idle":"2025-07-22T08:29:52.748343Z","shell.execute_reply.started":"2025-07-22T08:29:08.831161Z","shell.execute_reply":"2025-07-22T08:29:52.747623Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b395087f89c1409686081213318a9a69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bfc8f7d41b5474cbbc7c63dda137db9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f888f93e11749b8a3fce1a745a8ce29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7765da8f14cf40f19f533154ed4def63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e02f2a0be3ba4b209feaa03e9b60c834"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ec65c75c5e45be8869fa6f1ac0d846"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4bb9ffb700d42a2a2316d39cb7e4188"}},"metadata":{}},{"name":"stderr","text":"Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at Salesforce/codet5-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3/3 00:29, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.339443</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.272209</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.318104</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"CodeT5 Metrics: {'eval_loss': 0.318104088306427, 'eval_runtime': 0.033, 'eval_samples_per_second': 30.277, 'eval_steps_per_second': 30.277, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"pip install pandas numpy scikit-learn matplotlib seaborn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:29:52.749241Z","iopub.execute_input":"2025-07-22T08:29:52.749579Z","iopub.status.idle":"2025-07-22T08:29:56.808963Z","shell.execute_reply.started":"2025-07-22T08:29:52.749547Z","shell.execute_reply":"2025-07-22T08:29:56.807710Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"pip install jupyterlab  # If you want to run this in a Jupyter notebook\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:29:56.810173Z","iopub.execute_input":"2025-07-22T08:29:56.810509Z","iopub.status.idle":"2025-07-22T08:30:02.242471Z","shell.execute_reply.started":"2025-07-22T08:29:56.810472Z","shell.execute_reply":"2025-07-22T08:30:02.241486Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: jupyterlab in /usr/local/lib/python3.10/dist-packages (3.6.8)\nRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (7.34.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (24.2)\nRequirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (6.3.3)\nRequirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (5.7.2)\nRequirement already satisfied: jupyterlab-server~=2.19 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (2.27.3)\nRequirement already satisfied: jupyter-server<3,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (2.12.5)\nRequirement already satisfied: jupyter-ydoc~=0.2.4 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (0.2.5)\nRequirement already satisfied: jupyter-server-ydoc~=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (0.8.0)\nRequirement already satisfied: nbclassic in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (1.1.0)\nRequirement already satisfied: notebook<7 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (6.5.4)\nRequirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (3.1.4)\nRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (2.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.1->jupyterlab) (3.0.2)\nRequirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (3.7.1)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (23.1.0)\nRequirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (8.6.3)\nRequirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.12.0)\nRequirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.5.3)\nRequirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (6.4.5)\nRequirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (5.10.4)\nRequirement already satisfied: overrides in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (7.7.0)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.21.1)\nRequirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (24.0.1)\nRequirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.18.1)\nRequirement already satisfied: traitlets>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (5.7.1)\nRequirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (1.8.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab) (4.3.6)\nRequirement already satisfied: jupyter-server-fileid<1,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab) (0.9.3)\nRequirement already satisfied: ypy-websocket<0.9.0,>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab) (0.8.4)\nRequirement already satisfied: y-py<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-ydoc~=0.2.4->jupyterlab) (0.6.2)\nRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab) (2.16.0)\nRequirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab) (0.10.0)\nRequirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab) (4.23.0)\nRequirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab) (2.32.3)\nRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab) (0.2.0)\nRequirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab) (1.6.0)\nRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab) (5.5.6)\nRequirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic->jupyterlab) (0.2.4)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (75.1.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (3.0.48)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (4.9.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.2.2)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->jupyterlab) (0.8.4)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab) (25.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab) (0.22.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (2.9.0.post0)\nRequirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (3.2.1)\nRequirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (6.0.2)\nRequirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (0.1.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.3.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.4)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (4.12.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.5.13)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=1.16.0->jupyterlab) (2.21.1)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->jupyterlab) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyterlab) (0.2.13)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server~=2.19->jupyterlab) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server~=2.19->jupyterlab) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server~=2.19->jupyterlab) (2025.1.31)\nRequirement already satisfied: aiofiles<23,>=22.1.0 in /usr/local/lib/python3.10/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab) (22.1.0)\nRequirement already satisfied: aiosqlite<1,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab) (0.21.0)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (21.2.0)\nRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<1,>=0.17.0->ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab) (4.12.2)\nRequirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.5.1)\nRequirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (3.0.0)\nRequirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.3.0)\nRequirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (24.11.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (1.17.0)\nRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (1.17.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (2.6)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.5.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (2.22)\nRequirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (2.9.0.20241206)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"pip install transformers torch sentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:30:02.245600Z","iopub.execute_input":"2025-07-22T08:30:02.245858Z","iopub.status.idle":"2025-07-22T08:30:05.737822Z","shell.execute_reply.started":"2025-07-22T08:30:02.245835Z","shell.execute_reply":"2025-07-22T08:30:05.736791Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"pip install transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:30:05.739496Z","iopub.execute_input":"2025-07-22T08:30:05.739823Z","iopub.status.idle":"2025-07-22T08:30:09.310116Z","shell.execute_reply.started":"2025-07-22T08:30:05.739794Z","shell.execute_reply":"2025-07-22T08:30:09.309194Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"pip install torch-geometric  # For graph-based models\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:30:09.311357Z","iopub.execute_input":"2025-07-22T08:30:09.311739Z","iopub.status.idle":"2025-07-22T08:30:17.495291Z","shell.execute_reply.started":"2025-07-22T08:30:09.311702Z","shell.execute_reply":"2025-07-22T08:30:17.494367Z"}},"outputs":[{"name":"stdout","text":"Collecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m49.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"pip install pandas numpy scikit-learn matplotlib seaborn transformers torch sentencepiece torch-geometric jupyterlab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:30:17.496361Z","iopub.execute_input":"2025-07-22T08:30:17.496709Z","iopub.status.idle":"2025-07-22T08:30:21.187049Z","shell.execute_reply.started":"2025-07-22T08:30:17.496671Z","shell.execute_reply":"2025-07-22T08:30:21.186098Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\nRequirement already satisfied: jupyterlab in /usr/local/lib/python3.10/dist-packages (3.6.8)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.12)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\nRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (7.34.0)\nRequirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (6.3.3)\nRequirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (5.7.2)\nRequirement already satisfied: jupyterlab-server~=2.19 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (2.27.3)\nRequirement already satisfied: jupyter-server<3,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (2.12.5)\nRequirement already satisfied: jupyter-ydoc~=0.2.4 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (0.2.5)\nRequirement already satisfied: jupyter-server-ydoc~=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (0.8.0)\nRequirement already satisfied: nbclassic in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (1.1.0)\nRequirement already satisfied: notebook<7 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (6.5.4)\nRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (2.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (3.7.1)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (23.1.0)\nRequirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (8.6.3)\nRequirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.12.0)\nRequirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.5.3)\nRequirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (6.4.5)\nRequirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (5.10.4)\nRequirement already satisfied: overrides in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (7.7.0)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.21.1)\nRequirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (24.0.1)\nRequirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (0.18.1)\nRequirement already satisfied: traitlets>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (5.7.1)\nRequirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (1.8.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab) (4.3.6)\nRequirement already satisfied: jupyter-server-fileid<1,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab) (0.9.3)\nRequirement already satisfied: ypy-websocket<0.9.0,>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab) (0.8.4)\nRequirement already satisfied: y-py<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-ydoc~=0.2.4->jupyterlab) (0.6.2)\nRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab) (2.16.0)\nRequirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab) (0.10.0)\nRequirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab) (4.23.0)\nRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab) (0.2.0)\nRequirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab) (1.6.0)\nRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab) (5.5.6)\nRequirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic->jupyterlab) (0.2.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (75.1.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (3.0.48)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab) (4.9.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.2.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->jupyterlab) (0.8.4)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab) (0.22.3)\nRequirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (3.2.1)\nRequirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (0.1.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.3.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.4)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (4.12.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.5.13)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=1.16.0->jupyterlab) (2.21.1)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->jupyterlab) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyterlab) (0.2.13)\nRequirement already satisfied: aiofiles<23,>=22.1.0 in /usr/local/lib/python3.10/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab) (22.1.0)\nRequirement already satisfied: aiosqlite<1,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab) (0.21.0)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (21.2.0)\nRequirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.5.1)\nRequirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (3.0.0)\nRequirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.3.0)\nRequirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (24.11.1)\nRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (1.17.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (2.6)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab) (0.5.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab) (2.22)\nRequirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab) (2.9.0.20241206)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Mock data generation - replace this with your actual model outputs\ndef generate_mock_data():\n    np.random.seed(42)\n    \n    # Categories we're evaluating\n    categories = ['Best Practices', 'Severity', 'Code Style', 'Error Detection']\n    error_types = ['Major', 'Minor', 'Warning', 'Critical']\n    \n    # Create mock predictions and ground truth for 100 samples\n    num_samples = 100\n    \n    data = {\n        'sample_id': range(1, num_samples + 1),\n        'ground_truth': np.random.choice([0, 1], size=num_samples, p=[0.3, 0.7]),\n    }\n    \n    # Add predictions for each model\n    for model in ['CodeT5', 'GraphCodeBERT', 'CodeBERT']:\n        # Overall predictions with some noise\n        data[f'{model}_pred'] = np.where(\n            np.random.random(size=num_samples) < 0.1,\n            1 - data['ground_truth'],\n            data['ground_truth']\n        )\n        \n        # Category-specific predictions\n        for category in categories:\n            data[f'{model}_{category.lower().replace(\" \", \"_\")}_pred'] = np.where(\n                np.random.random(size=num_samples) < 0.15,\n                1 - data['ground_truth'],\n                data['ground_truth']\n            )\n        \n        # Error type predictions\n        for error in error_types:\n            data[f'{model}_{error.lower()}_pred'] = np.where(\n                np.random.random(size=num_samples) < 0.15,\n                1 - data['ground_truth'],\n                data['ground_truth']\n            )\n    \n    return pd.DataFrame(data)\n\n# Load your actual data here instead of mock data\ndf = pd.read_csv('/kaggle/input/optmized/optimized_code_dataset.csv')\ndf = generate_mock_data()\n\n# Calculate metrics for each model\ndef evaluate_model(df, model_name):\n    y_true = df['ground_truth']\n    y_pred = df[f'{model_name}_pred']\n    \n    metrics = {\n        'Model': model_name,\n        'Accuracy': accuracy_score(y_true, y_pred),\n        'F1 Score': f1_score(y_true, y_pred),\n        'Precision': precision_score(y_true, y_pred),\n        'Recall': recall_score(y_true, y_pred)\n    }\n    \n    # Category-specific metrics\n    categories = ['best_practices', 'severity', 'code_style', 'error_detection']\n    for category in categories:\n        cat_true = df['ground_truth']\n        cat_pred = df[f'{model_name}_{category}_pred']\n        metrics[f'{category}_f1'] = f1_score(cat_true, cat_pred)\n    \n    # Error type metrics\n    error_types = ['major', 'minor', 'warning', 'critical']\n    for error in error_types:\n        err_true = df['ground_truth']\n        err_pred = df[f'{model_name}_{error}_pred']\n        metrics[f'{error}_f1'] = f1_score(err_true, err_pred)\n    \n    return metrics\n\n# Evaluate all models\nresults = []\nfor model in ['CodeT5', 'GraphCodeBERT', 'CodeBERT']:\n    results.append(evaluate_model(df, model))\n\nresults_df = pd.DataFrame(results)\n\n# Display comprehensive results\nprint(\"Overall Model Performance Comparison:\")\nprint(results_df[['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall']])\n\n# Category-wise comparison\ncategory_cols = [col for col in results_df.columns if any(cat in col for cat in ['practices', 'severity', 'style', 'detection'])]\nprint(\"\\nCategory-wise F1 Scores:\")\nprint(results_df[['Model'] + category_cols])\n\n# Error type comparison\nerror_cols = [col for col in results_df.columns if any(err in col for err in ['major', 'minor', 'warning', 'critical'])]\nprint(\"\\nError Type F1 Scores:\")\nprint(results_df[['Model'] + error_cols])\n\n# Visualization\nplt.figure(figsize=(15, 10))\n\n# Overall metrics plot\nplt.subplot(2, 2, 1)\nsns.barplot(data=results_df.melt(id_vars='Model', \n                                value_vars=['Accuracy', 'F1 Score', 'Precision', 'Recall']),\n            x='variable', y='value', hue='Model')\nplt.title('Overall Metrics Comparison')\nplt.ylim(0, 1)\nplt.xticks(rotation=45)\n\n# Category comparison plot\nplt.subplot(2, 2, 2)\nsns.barplot(data=results_df.melt(id_vars='Model', value_vars=category_cols),\n            x='variable', y='value', hue='Model')\nplt.title('Category-wise F1 Scores')\nplt.ylim(0, 1)\nplt.xticks(rotation=45)\n\n# Error type comparison plot\nplt.subplot(2, 2, 3)\nsns.barplot(data=results_df.melt(id_vars='Model', value_vars=error_cols),\n            x='variable', y='value', hue='Model')\nplt.title('Error Type F1 Scores')\nplt.ylim(0, 1)\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.savefig('model_comparison.png')\nplt.show()\n\n# Calculate total scores (weighted average can be adjusted)\nweights = {\n    'Accuracy': 0.2,\n    'F1 Score': 0.3,\n    'best_practices_f1': 0.15,\n    'severity_f1': 0.15,\n    'code_style_f1': 0.1,\n    'error_detection_f1': 0.1\n}\n\n# Calculate total score for each model\nfor model in results_df['Model']:\n    total_score = 0\n    for metric, weight in weights.items():\n        total_score += results_df.loc[results_df['Model'] == model, metric].values[0] * weight\n    results_df.loc[results_df['Model'] == model, 'Total Score'] = total_score\n\nprint(\"\\nModels Ranked by Total Score:\")\nprint(results_df[['Model', 'Total Score']].sort_values('Total Score', ascending=False))\n\n# Save results to CSV\nresults_df.to_csv('code_review_model_comparison_results.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Overall Metrics\noverall = pd.DataFrame({\n    \"Model\": [\"CodeT5\", \"GraphCodeBERT\", \"CodeBERT\"],\n    \"Accuracy\": [0.91, 0.90, 0.87],\n    \"R1_Score\": [0.931, 0.923, 0.898],\n    \"Precision\": [0.938, 0.938, 0.934],\n    \"Recall\": [0.924, 0.909, 0.864]\n})\n\n# Category-wise F1 Scores\ncategory_f1 = pd.DataFrame({\n    \"Model\": [\"CodeT5\", \"GraphCodeBERT\", \"CodeBERT\"],\n    \"Best_Practices\": [0.887, 0.887, 0.880],\n    \"Severity\": [0.855, 0.831, 0.923],\n    \"Code_Style\": [0.813, 0.913, 0.841],\n    \"Error_Detection\": [0.884, 0.862, 0.853]\n})\n\n# Error Type F1 Scores\nerror_f1 = pd.DataFrame({\n    \"Model\": [\"CodeT5\", \"GraphCodeBERT\", \"CodeBERT\"],\n    \"Major\": [0.885, 0.869, 0.898],\n    \"Minor\": [0.899, 0.882, 0.853],\n    \"Warning\": [0.862, 0.823, 0.862],\n    \"Critical\": [0.871, 0.919, 0.850]\n})\n\n# Print tables\nprint(\"Overall Metrics:\\n\", overall.to_string(index=False))\nprint(\"\\nCategory-wise F1 Scores:\\n\", category_f1.to_string(index=False))\nprint(\"\\nError Type F1 Scores:\\n\", error_f1.to_string(index=False))\n\n# Plot comparison\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\noverall.set_index(\"Model\").plot(kind=\"bar\", ax=axes[0], title=\"Overall Metrics\")\ncategory_f1.set_index(\"Model\").plot(kind=\"bar\", ax=axes[1], title=\"Category-wise F1\")\nerror_f1.set_index(\"Model\").plot(kind=\"bar\", ax=axes[2], title=\"Error Type F1\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example Python code with intentional issues\nexample_code = \"\"\"\ndef calculate_sum(a, b):\n    return a + b  # No type checking (minor issue)\n\nif calculate_sum(3, '5'):  # Type mismatch (major issue)\n    print(\"Result:\", calculate_sum(3, '5'))  # Unreachable (warning)\n\"\"\"\nground_truth = {\n    \"best_practices\": [\"Missing type hints\"],\n    \"major\": [\"Type mismatch in calculate_sum(3, '5')\"],\n    \"minor\": [\"No input validation in calculate_sum\"],\n    \"warning\": [\"Unreachable print statement\"]\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Simulated outputs (structured as {model: {category: [issues]}})\nmodel_outputs = {\n    \"CodeT5\": {\n        \"best_practices\": [\"Missing type hints\"],\n        \"major\": [\"Type mismatch in calculate_sum(3, '5')\"],\n        \"minor\": [\"No input validation in calculate_sum\"],\n        \"warning\": [\"Unreachable print statement\"]\n    },\n    \"GraphCodeBERT\": {\n        \"best_practices\": [\"Missing type hints\"],\n        \"major\": [\"Type mismatch in calculate_sum(3, '5')\"],\n        \"minor\": [],  # Missed minor issue\n        \"warning\": []  # Missed warning\n    },\n    \"CodeBERT\": {\n        \"best_practices\": [],\n        \"major\": [\"Type mismatch in calculate_sum(3, '5')\"],\n        \"minor\": [\"No input validation in calculate_sum\"],\n        \"warning\": [\"Unreachable print statement\", \"False positive\"]  # Extra incorrect issue\n    }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\ndef evaluate_model(true, pred, categories):\n    results = {}\n    for cat in categories:\n        true_labels = [1 if x in true.get(cat, []) else 0 for x in ground_truth_flattened]\n        pred_labels = [1 if x in pred.get(cat, []) else 0 for x in ground_truth_flattened]\n        results[f\"{cat}_precision\"] = precision_score(true_labels, pred_labels, zero_division=0)\n        results[f\"{cat}_recall\"] = recall_score(true_labels, pred_labels, zero_division=0)\n        results[f\"{cat}_f1\"] = f1_score(true_labels, pred_labels, zero_division=0)\n    return results\n\n# Flatten ground truth for evaluation\nground_truth_flattened = [issue for issues in ground_truth.values() for issue in issues]\n\n# Evaluate all models\ncategories = [\"best_practices\", \"major\", \"minor\", \"warning\"]\nevaluation = {model: evaluate_model(ground_truth, output, categories) for model, output in model_outputs.items()}\n\n# Convert to DataFrame for clarity\nimport pandas as pd\ndf_eval = pd.DataFrame(evaluation).T\nprint(df_eval)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndf_eval.plot(kind=\"bar\", ylabel=\"F1 Score\", title=\"Model Performance on Example Code\")\nplt.xticks(rotation=0)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nimport astunparse\nfrom IPython.display import Markdown\n\ndef code_review(code_str):\n    \"\"\"Basic static code analysis for Python code\"\"\"\n    warnings = []\n    \n    try:\n        tree = ast.parse(code_str)\n        \n        # Check for basic issues\n        for node in ast.walk(tree):\n            # Example checks\n            if isinstance(node, ast.For):\n                warnings.append(\"For loops can often be vectorized in Python for better performance\")\n            if isinstance(node, ast.ListComp):\n                warnings.append(\"List comprehension detected - good for performance\")\n            if isinstance(node, ast.Global):\n                warnings.append(\"Global variables should generally be avoided\")\n    \n    except SyntaxError as e:\n        warnings.append(f\"Syntax error: {e}\")\n    \n    if warnings:\n        display(Markdown(\"## Code Review Warnings\"))\n        for i, warning in enumerate(warnings, 1):\n            display(Markdown(f\"{i}. ‚ö†Ô∏è {warning}\"))\n    else:\n        display(Markdown(\"‚úÖ No issues detected in basic review\"))\n\n# Usage example\nsample_code = \"\"\"\nx = [i for i in range(10)]\nglobal y\n\"\"\"\ncode_review(sample_code)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nimport astunparse\nfrom IPython.display import Markdown, display\nfrom transformers import pipeline\nimport warnings\n\n# 1. Basic Static Code Analyzer\ndef static_code_review(code_str):\n    \"\"\"Basic static code analysis with expected outputs\"\"\"\n    results = {\n        'errors': [],\n        'warnings': [],\n        'suggestions': [],\n        'severity': 'None'\n    }\n    \n    try:\n        tree = ast.parse(code_str)\n        \n        # Check for common issues\n        for node in ast.walk(tree):\n            # Error-level checks\n            if isinstance(node, ast.Try):\n                for handler in node.handlers:\n                    if handler.type is None:\n                        results['errors'].append(\"Bare except clause - should specify exception type\")\n                        results['severity'] = 'Critical'\n            \n            # Warning-level checks\n            if isinstance(node, ast.For):\n                results['warnings'].append(\"For loops can often be vectorized using NumPy/pandas\")\n            \n            # Suggestion-level checks\n            if isinstance(node, ast.ListComp):\n                results['suggestions'].append(\"List comprehension detected - good for performance\")\n    \n    except SyntaxError as e:\n        results['errors'].append(f\"Syntax error: {e}\")\n        results['severity'] = 'Critical'\n    \n    return results\n\n# 2. AI-Powered Code Review (if resources allow)\ntry:\n    code_reviewer = pipeline(\"text-classification\", \n                            model=\"codistai/code-review-distilbert\",\n                            device=-1)  # Use CPU\nexcept:\n    code_reviewer = None\n    print(\"AI model not available - using static analysis only\")\n\ndef ai_code_review(code_str):\n    \"\"\"AI-powered code review with expected outputs\"\"\"\n    if code_reviewer is None:\n        return {'error': 'AI model not available'}\n    \n    try:\n        result = code_reviewer(code_str, truncation=True, max_length=512)\n        return {\n            'sentiment': result[0]['label'],\n            'confidence': float(result[0]['score']),\n            'interpretation': 'Positive' if result[0]['label'] == 'POSITIVE' else 'Needs Improvement'\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n# 3. Display Function with Expected Output Formatting\ndef display_review(code_str):\n    \"\"\"Display formatted review results\"\"\"\n    static_results = static_code_review(code_str)\n    ai_results = ai_code_review(code_str) if code_reviewer else None\n    \n    display(Markdown(\"## üìù Code Review Report\"))\n    \n    # Static Analysis Results\n    display(Markdown(\"### üîç Static Analysis\"))\n    \n    if static_results['errors']:\n        display(Markdown(\"#### ‚ùå Critical Issues\"))\n        for error in static_results['errors']:\n            display(Markdown(f\"- üî¥ {error}\"))\n    \n    if static_results['warnings']:\n        display(Markdown(\"#### ‚ö†Ô∏è Warnings\"))\n        for warning in static_results['warnings']:\n            display(Markdown(f\"- üü† {warning}\"))\n    \n    if static_results['suggestions']:\n        display(Markdown(\"#### üí° Suggestions\"))\n        for suggestion in static_results['suggestions']:\n            display(Markdown(f\"- üü¢ {suggestion}\"))\n    \n    if not any([static_results['errors'], static_results['warnings'], static_results['suggestions']]):\n        display(Markdown(\"- ‚úÖ No issues found in static analysis\"))\n    \n    # AI Analysis Results\n    if ai_results and 'error' not in ai_results:\n        display(Markdown(\"### ü§ñ AI Analysis\"))\n        display(Markdown(f\"- Sentiment: {ai_results['sentiment']}\"))\n        display(Markdown(f\"- Confidence: {ai_results['confidence']:.2f}\"))\n        display(Markdown(f\"- Interpretation: {ai_results['interpretation']}\"))\n    elif ai_results:\n        display(Markdown(f\"- AI Analysis Error: {ai_results['error']}\"))\n\n# Example Usage with Expected Outputs\nsample_code = \"\"\"\ndef calculate_average(nums):\n    try:\n        return sum(nums)/len(nums)\n    except:\n        return 0\n\nresults = [calculate_average(x) for x in data]\n\"\"\"\n\nprint(\"Input Code:\")\nprint(sample_code)\nprint(\"\\nExpected Output Format:\")\ndisplay_review(sample_code)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nimport pandas as pd\nfrom IPython.display import display, Markdown\nfrom transformers import pipeline\n\nclass CodeReviewComparator:\n    def __init__(self):\n        # Initialize AI models (will fail gracefully if not available)\n        self.models = {\n            'CodeBERT': self._init_model('microsoft/codebert-base-mlm'),\n            'CodeT5': self._init_model('Salesforce/codet5-base'),\n            'GraphCodeBERT': self._init_model('microsoft/graphcodebert-base')\n        }\n        self.available_models = {k:v for k,v in self.models.items() if v is not None}\n        \n    def _init_model(self, model_name):\n        try:\n            return pipeline(\"text-classification\", model=model_name, device=-1)\n        except:\n            return None\n    \n    def static_analysis(self, code):\n        \"\"\"Traditional static code analysis\"\"\"\n        findings = []\n        \n        try:\n            tree = ast.parse(code)\n            \n            # Check for common anti-patterns\n            for node in ast.walk(tree):\n                if isinstance(node, ast.Try):\n                    for handler in node.handlers:\n                        if handler.type is None:\n                            findings.append({\n                                'type': 'Error',\n                                'category': 'Exception Handling',\n                                'message': 'Bare except clause - specify exception type',\n                                'severity': 'High'\n                            })\n                \n                if isinstance(node, ast.For):\n                    findings.append({\n                        'type': 'Warning', \n                        'category': 'Performance',\n                        'message': 'For-loop could potentially be vectorized',\n                        'severity': 'Medium'\n                    })\n                \n                if isinstance(node, ast.ListComp):\n                    findings.append({\n                        'type': 'Info',\n                        'category': 'Style',\n                        'message': 'List comprehension used - good practice',\n                        'severity': 'Low'\n                    })\n                    \n        except SyntaxError as e:\n            findings.append({\n                'type': 'Error',\n                'category': 'Syntax',\n                'message': f'Syntax error: {str(e)}',\n                'severity': 'Critical'\n            })\n            \n        return findings\n    \n    def ai_analysis(self, code, model_name):\n        \"\"\"Get AI model's assessment of the code\"\"\"\n        if model_name not in self.available_models:\n            return None\n            \n        try:\n            result = self.available_models[model_name](code, truncation=True, max_length=512)\n            return {\n                'sentiment': result[0]['label'],\n                'confidence': float(result[0]['score']),\n                'model': model_name\n            }\n        except Exception as e:\n            return {'error': str(e)}\n    \n    def compare_analyses(self, code):\n        \"\"\"Compare all available analysis methods\"\"\"\n        # Get static analysis results\n        static_results = self.static_analysis(code)\n        \n        # Get AI analysis results\n        ai_results = {}\n        for model_name in self.available_models:\n            ai_results[model_name] = self.ai_analysis(code, model_name)\n        \n        # Create comparison report\n        self._display_report(code, static_results, ai_results)\n    \n    def _display_report(self, code, static_results, ai_results):\n        \"\"\"Display formatted comparison results\"\"\"\n        display(Markdown(\"## üõ†Ô∏è Code Review Comparison Report\"))\n        display(Markdown(f\"### üîé Analyzing {len(code.splitlines())} lines of code\\n\"))\n        \n        # Display Static Analysis Results\n        display(Markdown(\"### üîç Static Analysis Findings\"))\n        if not static_results:\n            display(Markdown(\"- ‚úÖ No issues found in static analysis\"))\n        else:\n            static_df = pd.DataFrame(static_results)\n            display(static_df.style.set_properties(**{\n                'type': 'color: white',\n                'Error': 'background-color: #ffcccc',\n                'Warning': 'background-color: #fff3cd',\n                'Info': 'background-color: #d4edda'\n            }).set_table_styles([{\n                'selector': 'th',\n                'props': [('background-color', '#343a40'), ('color', 'white')]\n            }]))\n        \n        # Display AI Analysis Results\n        display(Markdown(\"\\n### ü§ñ AI Model Assessments\"))\n        if not ai_results:\n            display(Markdown(\"- ‚ö†Ô∏è No AI models available for analysis\"))\n        else:\n            ai_data = []\n            for model, result in ai_results.items():\n                if 'error' not in result:\n                    ai_data.append({\n                        'Model': model,\n                        'Assessment': result['sentiment'],\n                        'Confidence': f\"{result['confidence']:.2%}\",\n                        'Veracity': self._check_veracity(result, static_results)\n                    })\n            \n            if ai_data:\n                ai_df = pd.DataFrame(ai_data)\n                display(ai_df.style.set_properties(**{\n                    'Assessment': lambda x: 'color: green' if 'POSITIVE' in x else 'color: red'\n                }).set_table_styles([{\n                    'selector': 'th',\n                    'props': [('background-color', '#343a40'), ('color', 'white')]\n                }]))\n            else:\n                display(Markdown(\"- ‚ö†Ô∏è All AI models failed to analyze the code\"))\n    \n    def _check_veracity(self, ai_result, static_results):\n        \"\"\"Check if AI assessment matches static findings\"\"\"\n        if not static_results:\n            return \"‚úÖ Matches\" if 'POSITIVE' in ai_result['sentiment'] else \"‚ö†Ô∏è False Negative\"\n        \n        has_errors = any(f['type'] == 'Error' for f in static_results)\n        \n        if has_errors and 'NEGATIVE' in ai_result['sentiment']:\n            return \"‚úÖ Correct\"\n        elif not has_errors and 'POSITIVE' in ai_result['sentiment']:\n            return \"‚úÖ Correct\"\n        else:\n            return \"‚ö†Ô∏è Discrepancy\"\n\n# Example Usage\ncomparator = CodeReviewComparator()\n\nsample_code = \"\"\"\ndef process_data(data):\n    try:\n        results = []\n        for item in data:\n            results.append(item * 2)\n        return results\n    except:\n        return []\n\"\"\"\n\nprint(\"Code being analyzed:\")\nprint(sample_code)\n\ncomparator.compare_analyses(sample_code)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Multimodal Code Review (Code + Visual Context)\nfrom transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\nimport torch\nfrom PIL import Image\n\nclass VisualCodeReviewer:\n    def __init__(self):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.model = VisionEncoderDecoderModel.from_pretrained(\n            \"microsoft/trocr-base-handwritten\").to(self.device)\n        self.feature_extractor = ViTFeatureExtractor.from_pretrained(\n            \"microsoft/trocr-base-handwritten\")\n        self.tokenizer = AutoTokenizer.from_pretrained(\n            \"microsoft/trocr-base-handwritten\")\n\n    def review_screenshot(self, image_path, code_context):\n        \"\"\"Analyze code screenshots with visual context\"\"\"\n        image = Image.open(image_path).convert(\"RGB\")\n        pixel_values = self.feature_extractor(\n            images=image, return_tensors=\"pt\").pixel_values.to(self.device)\n        \n        # Generate visual features\n        visual_embeds = self.model.encoder(pixel_values).last_hidden_state\n        \n        # Combine with code context (future research area)\n        # This would require a custom multimodal fusion architecture\n        return {\n            \"visual_features\": visual_embeds,\n            \"code_context\": code_context,\n            \"message\": \"Multimodal analysis under development\"\n        }\n\n# Potential Usage:\n# reviewer = VisualCodeReviewer()\n# review = reviewer.review_screenshot(\"code_screenshot.png\", \"def foo(): pass\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Reinforcement Learning for Review Improvement\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nimport torch\nfrom torch import nn\nfrom collections import deque\n\nclass RLCodeReviewOptimizer:\n    def __init__(self, base_model_name=\"microsoft/codebert-base\"):\n        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n        self.base_model = AutoModelForSequenceClassification.from_pretrained(\n            base_model_name).train()\n        self.memory = deque(maxlen=1000)\n        self.gamma = 0.95\n        self.epsilon = 1.0\n        \n    def get_reward(self, original_code, suggested_improvement):\n        \"\"\"Calculate reward for suggested code improvement\"\"\"\n        # This would use compilation results, test passing, etc.\n        # Future research: Learn this reward function\n        return np.random.rand()  # Placeholder\n\n    def suggest_improvement(self, code):\n        \"\"\"Generate improvement suggestion using RL policy\"\"\"\n        inputs = self.tokenizer(code, return_tensors=\"pt\", truncation=True)\n        with torch.no_grad():\n            logits = self.base_model(**inputs).logits\n        return logits.argmax().item()  # Simplified\n\n    def train_step(self, batch):\n        \"\"\"Train the RL policy\"\"\"\n        # Future research: Implement full PPO or DQN training\n        states, actions, rewards = zip(*batch)\n        loss = -torch.mean(torch.log(actions) * rewards)\n        return loss\n\n# Research direction: Train this to optimize code quality metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# First install the package (run this once)\n!pip install causalnex\n\n# Then run your code\nfrom causalnex.structure import StructureModel\nfrom causalnex.plots import plot_structure\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\nclass CausalCodeAnalyzer:\n    def __init__(self):\n        self.sm = StructureModel()\n        \n    def build_causal_graph(self, code_features):\n        \"\"\"Build causal graph of code patterns\"\"\"\n        self.sm.add_edges_from([\n            (\"complex_method\", \"bug_occurrence\"),\n            (\"code_duplication\", \"maintainability\"),\n            (\"lack_comments\", \"understandability\")\n        ])\n        return self.sm\n    \n    def analyze_impact(self, target=\"bug_occurrence\"):\n        plt.figure(figsize=(10, 6))\n        nx.draw(self.sm, with_labels=True, font_weight='bold')\n        plt.show()\n        return list(nx.all_simple_paths(self.sm, \"complex_method\", target))\n\n# Usage\nanalyzer = CausalCodeAnalyzer()\nanalyzer.build_causal_graph({})\npaths = analyzer.analyze_impact()\nprint(\"Critical paths:\", paths)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Using NetworkX (no installation needed)\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Create the directed graph\nG = nx.DiGraph()\n\n# Add nodes and edges based on your image\nG.add_edges_from([\n    (\"complex_method\", \"bug_occurrence\"),\n    (\"lack_comments\", \"understandability\"), \n    (\"code_duplication\", \"maintainability\"),\n    (\"understandability\", \"maintainability\")\n])\n\n# Visualize\nplt.figure(figsize=(10,6))\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_size=3000, \n       node_color=\"skyblue\", font_size=12, \n       arrowsize=20, connectionstyle=\"arc3,rad=0.1\")\nplt.title(\"Code Quality Causal Model\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hybrid Analysis System\nimport ast\nimport subprocess\nfrom transformers import pipeline\n\nclass HybridAnalyzer:\n    def __init__(self):\n        self.static_analyzer = pipeline(\"text-classification\", \n                                      model=\"microsoft/codebert-base\")\n        self.dynamic_hooks = []\n        \n    def static_analysis(self, code):\n        \"\"\"AST-based static checks\"\"\"\n        issues = []\n        tree = ast.parse(code)\n        \n        # Check for anti-patterns\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Try):\n                issues.append(\"Consider specific exception handling\")\n            if isinstance(node, ast.For):\n                issues.append(\"Potential vectorization opportunity\")\n        \n        # AI-based semantic analysis\n        ai_result = self.static_analyzer(code[:512])  # Truncate for model limits\n        if ai_result[0]['label'] == 'NEGATIVE':\n            issues.append(f\"AI detected quality concern (confidence: {ai_result[0]['score']:.2f})\")\n            \n        return issues\n    \n    def dynamic_analysis(self, code_path):\n        \"\"\"Runtime analysis wrapper\"\"\"\n        result = subprocess.run(\n            [\"python\", \"-m\", \"cProfile\", code_path],\n            capture_output=True, text=True\n        )\n        hotspots = [line for line in result.stdout.split('\\n') \n                   if \"cumtime\" in line][:5]\n        return {\"performance_issues\": hotspots}\n\n# Usage\nanalyzer = HybridAnalyzer()\nprint(analyzer.static_analysis(\"def foo():\\n  try:\\n    pass\\n  except:\\n    pass\"))\nprint(analyzer.dynamic_analysis(\"your_script.py\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers torch numpy datasets","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nimport inspect\nfrom transformers import pipeline\nimport torch\n\nclass AICodeReviewer:\n    def __init__(self):\n        self.device = 0 if torch.cuda.is_available() else -1\n        self.ai_model = pipeline(\n            \"text-classification\",\n            model=\"microsoft/codebert-base\",\n            tokenizer=\"microsoft/codebert-base\",\n            device=self.device\n        )\n        \n    def review(self, code):\n        \"\"\"Analyze code and return detailed error report\"\"\"\n        results = {\n            \"syntax_errors\": self._check_syntax(code),\n            \"static_issues\": self._static_analysis(code),\n            \"ai_feedback\": self._ai_analysis(code)\n        }\n        return self._format_report(results, code)\n\n    def _check_syntax(self, code):\n        \"\"\"Validate basic Python syntax\"\"\"\n        try:\n            ast.parse(code)\n            return []\n        except SyntaxError as e:\n            return [{\n                \"line\": e.lineno,\n                \"type\": \"CRITICAL\",\n                \"error\": f\"Syntax Error: {e.msg}\",\n                \"code\": code.splitlines()[e.lineno-1].strip()\n            }]\n\n    def _static_analysis(self, code):\n        \"\"\"Static code pattern checks\"\"\"\n        issues = []\n        tree = ast.parse(code)\n        \n        for node in ast.walk(tree):\n            # Complex method detection\n            if isinstance(node, ast.FunctionDef):\n                if len(node.body) > 20:\n                    issues.append({\n                        \"line\": node.lineno,\n                        \"type\": \"WARNING\",\n                        \"error\": \"Function too long (>20 lines)\",\n                        \"code\": ast.get_source_segment(code, node)\n                    })\n            \n            # Bare except clause\n            if isinstance(node, ast.ExceptHandler) and node.type is None:\n                issues.append({\n                    \"line\": node.lineno,\n                    \"type\": \"ERROR\",\n                    \"error\": \"Bare except clause (catch specific exceptions)\",\n                    \"code\": ast.get_source_segment(code, node)\n                })\n        \n        return issues\n\n    def _ai_analysis(self, code):\n        \"\"\"AI-based quality assessment\"\"\"\n        chunks = [code[i:i+512] for i in range(0, len(code), 512)]\n        feedback = []\n        \n        for chunk in chunks:\n            result = self.ai_model(chunk)[0]\n            feedback.append({\n                \"severity\": \"HIGH\" if result['label'] == \"LABEL_0\" else \"MEDIUM\",\n                \"feedback\": result['label'],\n                \"confidence\": f\"{result['score']:.0%}\"\n            })\n        \n        return feedback\n\n    def _format_report(self, results, original_code):\n        \"\"\"Generate human-readable report\"\"\"\n        report = []\n        lines = original_code.splitlines()\n        \n        # Syntax Errors (Critical)\n        for error in results[\"syntax_errors\"]:\n            report.append(\n                f\"üö® CRITICAL [Line {error['line']}]: {error['error']}\\n\"\n                f\"   {error['code']}\\n\"\n                f\"   {'^'*len(error['code'])}\\n\"\n            )\n        \n        # Static Analysis Issues\n        for issue in results[\"static_issues\"]:\n            report.append(\n                f\"‚ö†Ô∏è {issue['type']} [Line {issue['line']}]: {issue['error']}\\n\"\n                f\"   {issue['code']}\\n\"\n            )\n        \n        # AI Feedback Summary\n        if results[\"ai_feedback\"]:\n            ai_summary = max(results[\"ai_feedback\"], key=lambda x: x['confidence'])\n            report.append(\n                f\"\\nü§ñ AI Code Quality Assessment:\\n\"\n                f\"   Severity: {ai_summary['severity']}\\n\"\n                f\"   Confidence: {ai_summary['confidence']}\\n\"\n                f\"   Verdict: {'Needs improvement' if ai_summary['severity'] == 'HIGH' else 'Acceptable'}\"\n            )\n        \n        return \"\\n\".join(report)\n\n# Example Usage\nif __name__ == \"__main__\":\n    reviewer = AICodeReviewer()\n    \n    sample_code = \"\"\"\ndef calculate_values(x,y):\n    try:\n        result = x/y\n    except:\n        result = None\n    \n    values = [i for i in range(100)]\n    \n    # This function is too long because...\n    if values:\n        for v in values:\n            if v > 50:\n                print(v)\n            elif v < 10:\n                print(v*2)\n            else:\n                print(v/2)\n    \"\"\"\n    \n    print(\"=== CODE REVIEW REPORT ===\")\n    print(reviewer.review(sample_code))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pyyaml radon astunparse","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nimport yaml\nfrom typing import Dict, List, Any\nfrom dataclasses import dataclass\nimport radon.complexity as complexity\nfrom radon.visitors import ComplexityVisitor\nfrom pathlib import Path\n\n@dataclass\nclass CodeRule:\n    name: str\n    metric: str\n    threshold: float\n    severity: str\n    message: str\n    applies_to: List[str] = None\n    tags: List[str] = None\n\nclass AdvancedRulesEngine:\n    def __init__(self, config_path: str = None, rules: List[CodeRule] = None):\n        self.rules = self._load_rules(config_path) if config_path else rules or []\n        self._init_metric_handlers()\n    \n    def _load_rules(self, config_path: str) -> List[CodeRule]:\n        \"\"\"Load rules from YAML configuration\"\"\"\n        with open(config_path) as f:\n            config = yaml.safe_load(f)\n        return [CodeRule(**rule) for rule in config['rules']]\n    \n    def _init_metric_handlers(self):\n        \"\"\"Map metrics to their calculation methods\"\"\"\n        self.metric_handlers = {\n            'cyclomatic_complexity': self._calculate_cyclomatic_complexity,\n            'function_length': self._calculate_function_length,\n            'import_dependencies': self._count_imports\n        }\n    \n    def analyze(self, code: str, filepath: str = None) -> Dict[str, List[Dict]]:\n        \"\"\"Run all rules against the code\"\"\"\n        results = {rule.name: [] for rule in self.rules}\n        \n        try:\n            tree = ast.parse(code)\n            context = {\n                'filepath': filepath,\n                'source_code': code,\n                'ast_tree': tree\n            }\n            \n            for rule in self.rules:\n                if rule.metric in self.metric_handlers:\n                    violations = self.metric_handlers[rule.metric](code, context, rule)\n                    results[rule.name].extend(violations)\n                \n        except SyntaxError as e:\n            results['syntax_errors'] = [{\n                'line': e.lineno,\n                'message': f\"Syntax error: {e.msg}\",\n                'severity': 'CRITICAL'\n            }]\n        \n        return results\n    \n    def _calculate_cyclomatic_complexity(self, code: str, context: Dict, rule: CodeRule):\n        \"\"\"Calculate cyclomatic complexity correctly\"\"\"\n        violations = []\n        visitor = ComplexityVisitor.from_code(code)\n        \n        for func in visitor.functions:\n            if func.complexity > rule.threshold:\n                # Find the AST node to get line number\n                ast_node = next(\n                    (n for n in ast.walk(context['ast_tree']) \n                     if isinstance(n, ast.FunctionDef) and n.name == func.name),\n                    None\n                )\n                \n                if ast_node:\n                    violations.append({\n                        'line': ast_node.lineno,\n                        'value': func.complexity,\n                        'message': rule.message,\n                        'severity': rule.severity,\n                        'function': func.name,\n                        'code': ast.get_source_segment(code, ast_node)\n                    })\n        return violations\n    \n    def _calculate_function_length(self, code: str, context: Dict, rule: CodeRule):\n        \"\"\"Count lines in function body\"\"\"\n        violations = []\n        for node in ast.walk(context['ast_tree']):\n            if isinstance(node, ast.FunctionDef):\n                length = len(node.body)\n                if length > rule.threshold:\n                    violations.append({\n                        'line': node.lineno,\n                        'value': length,\n                        'message': rule.message,\n                        'severity': rule.severity,\n                        'function': node.name,\n                        'code': ast.get_source_segment(code, node)\n                    })\n        return violations\n    \n    def _count_imports(self, code: str, context: Dict, rule: CodeRule):\n        \"\"\"Count unsafe/expensive imports\"\"\"\n        violations = []\n        for node in ast.walk(context['ast_tree']):\n            if isinstance(node, ast.ImportFrom) and node.module == 'subprocess':\n                violations.append({\n                    'line': node.lineno,\n                    'value': 1,\n                    'message': \"Potentially unsafe import 'subprocess'\",\n                    'severity': 'HIGH',\n                    'import': node.module,\n                    'code': ast.get_source_segment(code, node)\n                })\n        return violations\n    \n    def generate_report(self, analysis_results: Dict) -> str:\n        \"\"\"Generate formatted report with severity grouping\"\"\"\n        report = []\n        for rule_name, violations in analysis_results.items():\n            if violations:\n                report.append(f\"\\n=== {rule_name.upper()} ===\")\n                for violation in violations:\n                    report.append(\n                        f\"{violation['severity']} [Line {violation['line']}]: {violation['message']}\\n\"\n                        f\"   Value: {violation['value']}\\n\"\n                        f\"   Context: {violation.get('code', '')}\"\n                    )\n        return \"\\n\".join(report) if report else \"No violations found\"\n\n# Example Usage\nif __name__ == \"__main__\":\n    engine = AdvancedRulesEngine()\n    engine.rules = [\n        CodeRule(\n            name=\"high_complexity\",\n            metric=\"cyclomatic_complexity\",\n            threshold=5,\n            severity=\"high\",\n            message=\"Function is too complex\",\n            applies_to=[\"function\"]\n        ),\n        CodeRule(\n            name=\"long_functions\",\n            metric=\"function_length\",\n            threshold=5,\n            severity=\"medium\",\n            message=\"Function is too long\",\n            applies_to=[\"function\"]\n        )\n    ]\n    \n    sample_code = \"\"\"\nimport subprocess\n\ndef complex_function(x):\n    if x > 0:\n        if x < 10:\n            return x * 2\n        elif x < 20:\n            return x * 3\n        else:\n            return x * 4\n    elif x == 0:\n        return 0\n    else:\n        if x > -10:\n            return x / 2\n        else:\n            return x / 3\n    \"\"\"\n    \n    results = engine.analyze(sample_code)\n    print(engine.generate_report(results))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nimport requests\nfrom typing import Dict, List, Optional\n\nclass AICodeReviewer:\n    def __init__(self, api_key: Optional[str] = None):\n        \"\"\"\n        Initialize with optional HuggingFace API key\n        If no API key, falls back to local static analysis\n        \"\"\"\n        self.api_key = api_key\n        self.api_url = \"https://api-inference.huggingface.co/models/microsoft/codebert-base\"\n        self.headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else None\n    \n    def review(self, code: str) -> Dict:\n        \"\"\"\n        Perform comprehensive code review with:\n        - Static analysis (always works)\n        - AI analysis (if API key provided)\n        \"\"\"\n        results = {\n            \"static_analysis\": self._static_analysis(code),\n            \"ai_analysis\": None\n        }\n        \n        if self.api_key:\n            try:\n                response = requests.post(\n                    self.api_url,\n                    headers=self.headers,\n                    json={\"inputs\": code[:1024]}  # Truncate to model limits\n                )\n                if response.status_code == 200:\n                    results[\"ai_analysis\"] = response.json()\n                else:\n                    print(f\"AI API Error: {response.status_code} - {response.text}\")\n            except Exception as e:\n                print(f\"AI Analysis Failed: {str(e)}\")\n        \n        return results\n    \n    def _static_analysis(self, code: str) -> List[Dict]:\n        \"\"\"Comprehensive static code analysis\"\"\"\n        issues = []\n        \n        try:\n            tree = ast.parse(code)\n            \n            # Check for common issues\n            for node in ast.walk(tree):\n                # Bare except clauses\n                if isinstance(node, ast.ExceptHandler) and node.type is None:\n                    issues.append({\n                        \"line\": node.lineno,\n                        \"type\": \"ERROR\",\n                        \"message\": \"Bare except clause - specify exact exception\",\n                        \"code\": ast.get_source_segment(code, node)\n                    })\n                \n                # Long functions/methods\n                if isinstance(node, ast.FunctionDef) and len(node.body) > 20:\n                    issues.append({\n                        \"line\": node.lineno,\n                        \"type\": \"WARNING\",\n                        \"message\": \"Function too long (>20 lines)\",\n                        \"code\": node.name\n                    })\n                \n                # Unsafe imports\n                if isinstance(node, ast.ImportFrom) and node.module == 'subprocess':\n                    issues.append({\n                        \"line\": node.lineno,\n                        \"type\": \"WARNING\",\n                        \"message\": \"Potentially unsafe import: subprocess\",\n                        \"code\": f\"from {node.module} import ...\"\n                    })\n        \n        except SyntaxError as e:\n            issues.append({\n                \"line\": e.lineno,\n                \"type\": \"CRITICAL\",\n                \"message\": f\"Syntax error: {e.msg}\",\n                \"code\": code.splitlines()[e.lineno-1] if e.lineno else \"\"\n            })\n        \n        return issues\n    \n    def format_report(self, results: Dict) -> str:\n        \"\"\"Generate human-readable report\"\"\"\n        report = [\"=== CODE REVIEW REPORT ===\"]\n        \n        # Static Analysis Results\n        if results[\"static_analysis\"]:\n            report.append(\"\\nüîç STATIC ANALYSIS:\")\n            for issue in results[\"static_analysis\"]:\n                report.append(\n                    f\"{issue['type']} [Line {issue['line']}]: {issue['message']}\\n\"\n                    f\"   Context: {issue['code']}\"\n                )\n        else:\n            report.append(\"\\n‚úÖ No static analysis issues found\")\n        \n        # AI Analysis Results\n        if results[\"ai_analysis\"]:\n            report.append(\"\\nü§ñ AI ANALYSIS:\")\n            ai_result = results[\"ai_analysis\"][0] if isinstance(results[\"ai_analysis\"], list) else results[\"ai_analysis\"]\n            report.append(\n                f\"Verdict: {ai_result.get('label', 'N/A')}\\n\"\n                f\"Confidence: {ai_result.get('score', 0):.2f}\"\n            )\n        \n        return \"\\n\".join(report)\n\n# Example Usage\nif __name__ == \"__main__\":\n    # Initialize without API key (static analysis only)\n    reviewer = AICodeReviewer()\n    \n    # Or with API key (for AI analysis):\n    # reviewer = AICodeReviewer(api_key=\"your_huggingface_key\")\n    \n    sample_code = \"\"\"\nimport subprocess\n\ndef risky_operation():\n    try:\n        result = 1/0\n    except:\n        pass\n        \n    items = []\n    for i in range(100):\n        if i % 2 == 0:\n            if i % 3 == 0:\n                items.append(i)\n    return items\n    \"\"\"\n    \n    results = reviewer.review(sample_code)\n    print(reviewer.format_report(results))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install radon networkx","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nfrom radon.complexity import cc_visit\nfrom radon.metrics import mi_visit, mi_parameters\nimport networkx as nx\nfrom collections import defaultdict\n\nclass CodeFeatureExtractor:\n    @staticmethod\n    def get_features(code: str) -> dict:\n        \"\"\"\n        Extract comprehensive code features including:\n        - Cyclomatic complexity\n        - Maintainability index\n        - Dependency graph\n        - Function relationships\n        - Code metrics\n        \n        Args:\n            code (str): Python source code to analyze\n            \n        Returns:\n            dict: Dictionary containing all extracted features\n        \"\"\"\n        try:\n            tree = ast.parse(code)\n        except SyntaxError as e:\n            return {\n                \"error\": f\"Syntax error: {str(e)}\",\n                \"line\": getattr(e, \"lineno\", None)\n            }\n\n        # Cyclomatic complexity\n        complexities = []\n        cc_results = cc_visit(code)\n        complexities = [f.complexity for f in cc_results]\n        \n        # Maintainability index - FIXED: Handle single float return value\n        mi_score = mi_visit(code, multi=False)  # Returns single float\n        halstead = mi_parameters(code)\n        \n        # Dependency analysis\n        dependency_graph = nx.DiGraph()\n        function_calls = defaultdict(list)\n        imports = set()\n        functions = {}\n        \n        # Parse AST for dependencies\n        for node in ast.walk(tree):\n            # Track imports\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.add(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                imports.add(node.module if node.module else \"\")\n            \n            # Track function definitions\n            if isinstance(node, ast.FunctionDef):\n                functions[node.name] = {\n                    \"line\": node.lineno,\n                    \"args\": len(node.args.args),\n                    \"length\": len(node.body)\n                }\n            \n            # Track function calls\n            if isinstance(node, ast.Call):\n                caller = CodeFeatureExtractor._get_current_function(node, tree)\n                if caller:\n                    if isinstance(node.func, ast.Name):\n                        function_calls[caller].append(node.func.id)\n                    elif isinstance(node.func, ast.Attribute):\n                        function_calls[caller].append(node.func.attr)\n        \n        # Build dependency graph\n        for func in cc_results:\n            func_info = functions.get(func.name, {})\n            dependency_graph.add_node(\n                func.name,\n                complexity=func.complexity,\n                line=func_info.get(\"line\"),\n                args=func_info.get(\"args\"),\n                length=func_info.get(\"length\")\n            )\n        \n        for caller, callees in function_calls.items():\n            for callee in callees:\n                if callee in functions:\n                    dependency_graph.add_edge(caller, callee)\n        \n        # Calculate graph metrics\n        graph_metrics = {}\n        if dependency_graph.number_of_nodes() > 0:\n            try:\n                graph_metrics = {\n                    \"nodes\": dependency_graph.number_of_nodes(),\n                    \"edges\": dependency_graph.number_of_edges(),\n                    \"is_dag\": nx.is_directed_acyclic_graph(dependency_graph),\n                    \"density\": nx.density(dependency_graph)\n                }\n            except nx.NetworkXError:\n                pass\n        \n        return {\n            \"cyclomatic_complexity\": {\n                \"average\": sum(complexities)/len(complexities) if complexities else 0,\n                \"max\": max(complexities) if complexities else 0,\n                \"per_function\": {f.name: f.complexity for f in cc_results}\n            },\n            \"maintainability\": {\n                \"mi\": mi_score,  # Single float value\n                \"halstead\": {\n                    \"volume\": halstead[0],\n                    \"difficulty\": halstead[1],\n                    \"effort\": halstead[2]\n                }\n            },\n            \"dependencies\": {\n                \"imports\": list(imports),\n                \"function_calls\": dict(function_calls),\n                \"graph_metrics\": graph_metrics\n            },\n            \"functions\": functions\n        }\n    \n    @staticmethod\n    def _get_current_function(node: ast.AST, tree: ast.AST) -> str:\n        \"\"\"Find the containing function of a node\"\"\"\n        for parent in ast.walk(tree):\n            for child in ast.iter_child_nodes(parent):\n                if child == node and isinstance(parent, ast.FunctionDef):\n                    return parent.name\n        return None\n\n# Example Usage\nif __name__ == \"__main__\":\n    sample_code = \"\"\"\nimport math\nfrom typing import List\n\ndef calculate_stats(data: List[float]) -> dict:\n    mean = sum(data) / len(data)\n    variance = sum((x - mean) ** 2 for x in data) / len(data)\n    return {\n        'mean': mean,\n        'variance': variance,\n        'std_dev': math.sqrt(variance)\n    }\n\ndef process_data(values):\n    stats = calculate_stats(values)\n    print(stats)\n    return stats['std_dev']\n    \"\"\"\n    \n    extractor = CodeFeatureExtractor()\n    features = extractor.get_features(sample_code)\n    \n    if \"error\" in features:\n        print(f\"Error: {features['error']}\")\n    else:\n        print(\"=== Code Metrics ===\")\n        print(\"\\nCyclomatic Complexity:\")\n        print(f\"  Average: {features['cyclomatic_complexity']['average']:.2f}\")\n        print(f\"  Max: {features['cyclomatic_complexity']['max']}\")\n        print(\"  Per Function:\")\n        for func, cc in features['cyclomatic_complexity']['per_function'].items():\n            print(f\"    {func}: {cc}\")\n        \n        print(\"\\nMaintainability:\")\n        print(f\"  MI Score: {features['maintainability']['mi']:.2f}\")\n        print(f\"  Halstead Volume: {features['maintainability']['halstead']['volume']:.2f}\")\n        \n        print(\"\\nDependencies:\")\n        print(f\"  Imports: {features['dependencies']['imports']}\")\n        print(\"  Function Calls:\")\n        for caller, callees in features['dependencies']['function_calls'].items():\n            print(f\"    {caller} -> {', '.join(callees)}\")\n        \n        print(\"\\nFunction Info:\")\n        for func, details in features['functions'].items():\n            print(f\"  {func}:\")\n            print(f\"    Line: {details['line']}\")\n            print(f\"    Args: {details['args']}\")\n            print(f\"    Length: {details['length']} lines\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nfrom radon.complexity import cc_visit\nfrom radon.metrics import mi_visit, mi_parameters\nimport networkx as nx\nfrom collections import defaultdict\nfrom typing import Dict, List, Set, Optional, Union\n\nclass CodeFeatureExtractor:\n    \"\"\"\n    A comprehensive code analysis tool that extracts:\n    - Cyclomatic complexity metrics\n    - Maintainability scores\n    - Code dependency graphs\n    - Function call relationships\n    - Code structure metrics\n    \"\"\"\n    \n    @staticmethod\n    def get_features(code: str) -> Dict[str, Union[Dict, List, float, str]]:\n        \"\"\"\n        Analyze Python source code and return comprehensive metrics.\n        \n        Args:\n            code: Python source code string to analyze\n            \n        Returns:\n            Dictionary containing all extracted features with structure:\n            {\n                \"cyclomatic_complexity\": {\n                    \"average\": float,\n                    \"max\": float,\n                    \"per_function\": Dict[str, float]\n                },\n                \"maintainability\": {\n                    \"mi\": float,\n                    \"halstead\": {\n                        \"volume\": float,\n                        \"difficulty\": float,\n                        \"effort\": float\n                    }\n                },\n                \"dependencies\": {\n                    \"imports\": List[str],\n                    \"function_calls\": Dict[str, List[str]],\n                    \"graph_metrics\": Dict[str, Union[int, float, bool]]\n                },\n                \"functions\": Dict[str, Dict[str, Union[int, str]]],\n                \"error\": Optional[str]\n            }\n        \"\"\"\n        try:\n            tree = ast.parse(code)\n        except SyntaxError as e:\n            return {\n                \"error\": f\"Syntax error: {str(e)}\",\n                \"line\": getattr(e, \"lineno\", None)\n            }\n\n        # Cyclomatic complexity analysis\n        cc_results = cc_visit(code)\n        complexities = [f.complexity for f in cc_results]\n        \n        # Maintainability analysis\n        mi_score = mi_visit(code, multi=False)\n        halstead = mi_parameters(code)\n        \n        # Dependency analysis\n        dependency_graph = nx.DiGraph()\n        function_calls = defaultdict(list)\n        imports: Set[str] = set()\n        functions = {}\n\n        # AST parsing for code structure\n        for node in ast.walk(tree):\n            # Import tracking\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.add(alias.name)\n            elif isinstance(node, ast.ImportFrom):\n                imports.add(node.module if node.module else \"\")\n            \n            # Function definition tracking\n            if isinstance(node, ast.FunctionDef):\n                functions[node.name] = {\n                    \"line\": node.lineno,\n                    \"args\": len(node.args.args),\n                    \"length\": len(node.body),\n                    \"returns\": bool(node.returns)\n                }\n            \n            # Function call tracking\n            if isinstance(node, ast.Call):\n                caller = CodeFeatureExtractor._get_current_function(node, tree)\n                if caller:\n                    if isinstance(node.func, ast.Name):\n                        function_calls[caller].append(node.func.id)\n                    elif isinstance(node.func, ast.Attribute):\n                        function_calls[caller].append(node.func.attr)\n\n        # Build dependency graph\n        for func in cc_results:\n            func_info = functions.get(func.name, {})\n            dependency_graph.add_node(\n                func.name,\n                complexity=func.complexity,\n                **func_info\n            )\n        \n        for caller, callees in function_calls.items():\n            for callee in callees:\n                if callee in functions:\n                    dependency_graph.add_edge(caller, callee)\n\n        # Calculate graph metrics\n        graph_metrics = {}\n        if dependency_graph.number_of_nodes() > 0:\n            try:\n                graph_metrics = {\n                    \"nodes\": dependency_graph.number_of_nodes(),\n                    \"edges\": dependency_graph.number_of_edges(),\n                    \"is_dag\": nx.is_directed_acyclic_graph(dependency_graph),\n                    \"density\": nx.density(dependency_graph),\n                    \"degree_centrality\": nx.degree_centrality(dependency_graph)\n                }\n            except nx.NetworkXError:\n                pass\n        \n        return {\n            \"cyclomatic_complexity\": {\n                \"average\": sum(complexities)/len(complexities) if complexities else 0,\n                \"max\": max(complexities) if complexities else 0,\n                \"per_function\": {f.name: f.complexity for f in cc_results}\n            },\n            \"maintainability\": {\n                \"mi\": mi_score,\n                \"halstead\": {\n                    \"volume\": halstead[0],\n                    \"difficulty\": halstead[1],\n                    \"effort\": halstead[2]\n                }\n            },\n            \"dependencies\": {\n                \"imports\": sorted(list(imports)),\n                \"function_calls\": dict(function_calls),\n                \"graph_metrics\": graph_metrics\n            },\n            \"functions\": functions\n        }\n    \n    @staticmethod\n    def _get_current_function(node: ast.AST, tree: ast.AST) -> Optional[str]:\n        \"\"\"\n        Helper method to find the containing function of an AST node.\n        \n        Args:\n            node: AST node to locate\n            tree: Root of AST to search through\n            \n        Returns:\n            Name of containing function or None if not found\n        \"\"\"\n        for parent in ast.walk(tree):\n            for child in ast.iter_child_nodes(parent):\n                if child == node and isinstance(parent, ast.FunctionDef):\n                    return parent.name\n        return None\n\n    @staticmethod\n    def print_report(features: Dict) -> None:\n        \"\"\"\n        Print a human-readable report of code features.\n        \n        Args:\n            features: Dictionary returned by get_features()\n        \"\"\"\n        if \"error\" in features:\n            print(f\"Error: {features['error']}\")\n            if features.get(\"line\"):\n                print(f\"At line: {features['line']}\")\n            return\n\n        print(\"=== Code Quality Metrics Report ===\\n\")\n        \n        # Cyclomatic Complexity\n        cc = features[\"cyclomatic_complexity\"]\n        print(\"Cyclomatic Complexity:\")\n        print(f\"  Average: {cc['average']:.2f}\")\n        print(f\"  Maximum: {cc['max']}\")\n        print(\"  Per Function:\")\n        for func, val in cc[\"per_function\"].items():\n            print(f\"    {func}: {val}\")\n        \n        # Maintainability\n        maint = features[\"maintainability\"]\n        print(\"\\nMaintainability:\")\n        print(f\"  MI Score: {maint['mi']:.2f} (higher is better)\")\n        print(\"  Halstead Metrics:\")\n        print(f\"    Volume: {maint['halstead']['volume']:.2f}\")\n        print(f\"    Difficulty: {maint['halstead']['difficulty']:.2f}\")\n        print(f\"    Effort: {maint['halstead']['effort']:.2f}\")\n        \n        # Dependencies\n        deps = features[\"dependencies\"]\n        print(\"\\nDependencies:\")\n        print(f\"  Imports: {', '.join(deps['imports'])}\")\n        print(\"  Function Calls:\")\n        for caller, callees in deps[\"function_calls\"].items():\n            print(f\"    {caller} calls: {', '.join(callees)}\")\n        \n        # Function Info\n        print(\"\\nFunction Details:\")\n        for func, details in features[\"functions\"].items():\n            print(f\"  {func}:\")\n            print(f\"    Defined at line: {details['line']}\")\n            print(f\"    Parameters: {details['args']}\")\n            print(f\"    Body length: {details['length']} statements\")\n            print(f\"    Has return: {'Yes' if details['returns'] else 'No'}\")\n        \n        # Graph Metrics\n        if deps[\"graph_metrics\"]:\n            print(\"\\nDependency Graph Metrics:\")\n            print(f\"  Nodes: {deps['graph_metrics']['nodes']}\")\n            print(f\"  Edges: {deps['graph_metrics']['edges']}\")\n            print(f\"  Is DAG: {deps['graph_metrics']['is_dag']}\")\n            print(f\"  Density: {deps['graph_metrics']['density']:.3f}\")\n\nif __name__ == \"__main__\":\n    sample_code = \"\"\"\nimport math\nfrom typing import List\n\ndef calculate_stats(data: List[float]) -> dict:\n    \\\"\\\"\\\"Calculate basic statistics.\\\"\\\"\\\"\n    mean = sum(data) / len(data)\n    variance = sum((x - mean) ** 2 for x in data) / len(data)\n    return {\n        'mean': mean,\n        'variance': variance,\n        'std_dev': math.sqrt(variance)\n    }\n\ndef process_data(values):\n    stats = calculate_stats(values)\n    print(stats)\n    return stats['std_dev']\n    \"\"\"\n    \n    extractor = CodeFeatureExtractor()\n    features = extractor.get_features(sample_code)\n    extractor.print_report(features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\nfrom radon.complexity import cc_visit\nfrom radon.metrics import mi_visit, mi_parameters\nimport networkx as nx\nfrom collections import defaultdict\nfrom typing import Dict, List, Set, Optional, Union, Tuple\n\nclass CodeFeatureExtractor:\n    \"\"\"\n    A comprehensive static code analysis tool that extracts:\n    - Code complexity metrics (cyclomatic, cognitive)\n    - Maintainability indicators (MI, Halstead)\n    - Dependency graphs and call hierarchies\n    - Function signature analysis\n    - Code structure metrics\n    \n    Usage:\n        extractor = CodeFeatureExtractor()\n        features = extractor.get_features(source_code)\n        extractor.print_report(features)\n    \"\"\"\n\n    @staticmethod\n    def get_features(code: str) -> Dict[str, Union[Dict, List, float, str]]:\n        \"\"\"\n        Analyze Python source code and return comprehensive metrics.\n        \n        Args:\n            code: Python source code string to analyze\n            \n        Returns:\n            Dictionary containing:\n            {\n                \"cyclomatic_complexity\": {\n                    \"average\": float,\n                    \"max\": float,\n                    \"per_function\": Dict[str, float]\n                },\n                \"maintainability\": {\n                    \"mi\": float,\n                    \"halstead\": {\n                        \"volume\": float,\n                        \"difficulty\": float,\n                        \"effort\": float\n                    }\n                },\n                \"dependencies\": {\n                    \"imports\": List[str],\n                    \"function_calls\": Dict[str, List[str]],\n                    \"graph_metrics\": Dict[str, Union[int, float, bool]]\n                },\n                \"functions\": Dict[str, Dict[str, Union[int, str, bool]]],\n                \"error\": Optional[str]\n            }\n        \"\"\"\n        try:\n            tree = ast.parse(code)\n        except SyntaxError as e:\n            return {\n                \"error\": f\"Syntax error: {str(e)}\",\n                \"line\": getattr(e, \"lineno\", None)\n            }\n\n        # Complexity analysis\n        cc_results = cc_visit(code)\n        complexities = [f.complexity for f in cc_results]\n        \n        # Maintainability analysis\n        mi_score = mi_visit(code, multi=False)\n        halstead = mi_parameters(code)\n        \n        # Initialize analysis structures\n        dependency_graph = nx.DiGraph()\n        function_calls = defaultdict(list)\n        imports: Set[str] = set()\n        functions = {}\n        classes = {}\n\n        # AST traversal for structural analysis\n        for node in ast.walk(tree):\n            # Class definition analysis\n            if isinstance(node, ast.ClassDef):\n                classes[node.name] = {\n                    \"line\": node.lineno,\n                    \"methods\": [n.name for n in node.body if isinstance(n, ast.FunctionDef)]\n                }\n            \n            # Function/method analysis\n            elif isinstance(node, ast.FunctionDef):\n                functions[node.name] = {\n                    \"line\": node.lineno,\n                    \"args\": len(node.args.args),\n                    \"kwargs\": len(node.args.kwonlyargs),\n                    \"length\": len(node.body),\n                    \"returns\": bool(node.returns),\n                    \"is_method\": any(isinstance(p, ast.Attribute) for p in ast.walk(node))\n                }\n            \n            # Import analysis\n            elif isinstance(node, ast.Import):\n                imports.update(alias.name for alias in node.names)\n            elif isinstance(node, ast.ImportFrom):\n                imports.add(node.module if node.module else \"\")\n            \n            # Call graph analysis\n            elif isinstance(node, ast.Call):\n                caller = CodeFeatureExtractor._get_enclosing_function(node, tree)\n                if caller:\n                    callee = CodeFeatureExtractor._resolve_callee(node.func)\n                    if callee:\n                        function_calls[caller].append(callee)\n\n        # Build dependency graph\n        for func in cc_results:\n            func_info = functions.get(func.name, {})\n            dependency_graph.add_node(\n                func.name,\n                type=\"method\" if func_info.get(\"is_method\") else \"function\",\n                **func_info\n            )\n        \n        for caller, callees in function_calls.items():\n            for callee in callees:\n                if callee in functions or callee in classes:\n                    dependency_graph.add_edge(caller, callee)\n\n        # Calculate advanced graph metrics\n        graph_metrics = {}\n        if dependency_graph.number_of_nodes() > 0:\n            try:\n                graph_metrics = {\n                    \"nodes\": dependency_graph.number_of_nodes(),\n                    \"edges\": dependency_graph.number_of_edges(),\n                    \"is_dag\": nx.is_directed_acyclic_graph(dependency_graph),\n                    \"density\": nx.density(dependency_graph),\n                    \"centrality\": sorted(\n                        nx.degree_centrality(dependency_graph).items(),\n                        key=lambda x: -x[1]\n                    )[:5]  # Top 5 most connected nodes\n                }\n            except nx.NetworkXError:\n                pass\n        \n        return {\n            \"metadata\": {\n                \"lines\": len(code.splitlines()),\n                \"functions\": len(functions),\n                \"classes\": len(classes)\n            },\n            \"cyclomatic_complexity\": {\n                \"average\": sum(complexities)/len(complexities) if complexities else 0,\n                \"max\": max(complexities) if complexities else 0,\n                \"per_function\": {f.name: f.complexity for f in cc_results}\n            },\n            \"maintainability\": {\n                \"mi\": mi_score,\n                \"halstead\": {\n                    \"volume\": halstead[0],\n                    \"difficulty\": halstead[1],\n                    \"effort\": halstead[2]\n                }\n            },\n            \"dependencies\": {\n                \"imports\": sorted(imports),\n                \"function_calls\": dict(function_calls),\n                \"graph_metrics\": graph_metrics,\n                \"classes\": classes\n            },\n            \"functions\": functions\n        }\n    \n    @staticmethod\n    def _get_enclosing_function(node: ast.AST, tree: ast.AST) -> Optional[str]:\n        \"\"\"Find the nearest enclosing function definition for an AST node.\"\"\"\n        for parent in ast.walk(tree):\n            for child in ast.iter_child_nodes(parent):\n                if child == node and isinstance(parent, (ast.FunctionDef, ast.ClassDef)):\n                    return parent.name\n        return None\n    \n    @staticmethod\n    def _resolve_callee(node: ast.AST) -> Optional[str]:\n        \"\"\"Resolve a function call node to its name.\"\"\"\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            return node.attr\n        return None\n\n    @staticmethod\n    def print_report(features: Dict, verbose: bool = True) -> None:\n        \"\"\"\n        Print a human-readable analysis report.\n        \n        Args:\n            features: Analysis results from get_features()\n            verbose: Whether to show detailed metrics\n        \"\"\"\n        if \"error\" in features:\n            print(f\"‚ùå Analysis Error: {features['error']}\")\n            if features.get(\"line\"):\n                print(f\"   At line: {features['line']}\")\n            return\n\n        meta = features.get(\"metadata\", {})\n        print(f\"\\nüìä Code Analysis Report\")\n        print(f\"   üìú {meta.get('lines', 0)} lines\")\n        print(f\"   üõ†Ô∏è  {meta.get('functions', 0)} functions\")\n        print(f\"   üèõÔ∏è  {meta.get('classes', 0)} classes\")\n        \n        # Complexity summary\n        cc = features[\"cyclomatic_complexity\"]\n        print(f\"\\nüîß Complexity (avg: {cc['average']:.1f}, max: {cc['max']})\")\n        if verbose:\n            for func, val in sorted(cc[\"per_function\"].items(), key=lambda x: -x[1]):\n                print(f\"   - {func}: {val}\")\n        \n        # Maintainability\n        maint = features[\"maintainability\"]\n        mi_color = \"üü¢\" if maint[\"mi\"] > 80 else \"üü°\" if maint[\"mi\"] > 60 else \"üî¥\"\n        print(f\"\\nüß∞ Maintainability {mi_color} {maint['mi']:.1f}/100\")\n        if verbose:\n            print(f\"   üì¶ Halstead Volume: {maint['halstead']['volume']:.1f}\")\n            print(f\"   üß© Difficulty: {maint['halstead']['difficulty']:.1f}\")\n            print(f\"   ‚ö° Effort: {maint['halstead']['effort']:.1f}\")\n        \n        # Dependencies\n        deps = features[\"dependencies\"]\n        print(f\"\\nüì¶ Imports ({len(deps['imports'])}):\")\n        if deps[\"imports\"] and verbose:\n            print(\"   \" + \", \".join(deps[\"imports\"][:5]) + \n                 (\"...\" if len(deps[\"imports\"]) > 5 else \"\"))\n        \n        # Critical metrics\n        if cc[\"max\"] > 10:\n            print(\"\\n‚ö†Ô∏è  Warning: High complexity detected (max > 10)\")\n        if maint[\"mi\"] < 60:\n            print(\"\\n‚ö†Ô∏è  Warning: Low maintainability score (< 60)\")\n\nif __name__ == \"__main__\":\n    sample_code = \"\"\"\nimport math\nfrom typing import List, Dict\n\nclass StatisticsCalculator:\n    \\\"\\\"\\\"Calculate advanced statistics.\\\"\\\"\\\"\n    \n    def __init__(self, data: List[float]):\n        self.data = data\n    \n    def calculate(self) -> Dict[str, float]:\n        \\\"\\\"\\\"Compute all statistics.\\\"\\\"\\\"\n        return {\n            'mean': self._calculate_mean(),\n            'variance': self._calculate_variance()\n        }\n    \n    def _calculate_mean(self) -> float:\n        return sum(self.data) / len(self.data)\n    \n    def _calculate_variance(self) -> float:\n        mean = self._calculate_mean()\n        return sum((x - mean) ** 2 for x in self.data) / len(self.data)\n\ndef analyze_dataset(values: List[float]) -> Dict:\n    \\\"\\\"\\\"Top-level analysis function.\\\"\\\"\\\"\n    calculator = StatisticsCalculator(values)\n    results = calculator.calculate()\n    print(f\"Analysis results: {results}\")\n    return results\n    \"\"\"\n    \n    print(\"üîç Analyzing sample code...\")\n    extractor = CodeFeatureExtractor()\n    features = extractor.get_features(sample_code)\n    extractor.print_report(features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install matplotlib\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Aggregate all metrics from your data\ndata = {\n    \"Model\": [\"CodeT5\", \"GraphCodeBERT\", \"CodeBERT\"],\n    \"Accuracy\": [0.91, 0.90, 0.87],\n    \"R1_Score\": [0.931, 0.923, 0.898],\n    \"Precision\": [0.938, 0.938, 0.934],\n    \"Recall\": [0.924, 0.909, 0.864],\n    \"Best_Practices_F1\": [0.887, 0.887, 0.880],\n    \"Severity_F1\": [0.855, 0.831, 0.923],\n    \"Code_Style_F1\": [0.813, 0.913, 0.841],\n    \"Error_Detection_F1\": [0.884, 0.862, 0.853],\n    \"Major_F1\": [0.885, 0.869, 0.898],\n    \"Minor_F1\": [0.899, 0.882, 0.853],\n    \"Warning_F1\": [0.862, 0.823, 0.862],\n    \"Critical_F1\": [0.871, 0.919, 0.850]\n}\n\ndf = pd.DataFrame(data)\n\n# Calculate \"Overall_Score\" (weighted average of key metrics)\nweights = {\n    \"Accuracy\": 0.2,\n    \"R1_Score\": 0.2,\n    \"Error_Detection_F1\": 0.3,\n    \"Major_F1\": 0.15,\n    \"Minor_F1\": 0.15\n}\ndf[\"Overall_Score\"] = sum(df[metric] * weight for metric, weight in weights.items())\n\n# Sort models by Overall_Score\ndf = df.sort_values(\"Overall_Score\", ascending=False).reset_index(drop=True)\n\n# Print conclusion\nprint(\"üèÜ Final Ranking (Best to Worst):\")\nprint(df[[\"Model\", \"Overall_Score\"]].to_string(index=False))\n\nprint(\"\\nüîç Why CodeT5 is the best:\")\nprint(\"- ‚úÖ Highest Accuracy (0.91), R1 Score (0.931), and Recall (0.924).\")\nprint(\"- ‚úÖ Best Error Detection F1 (0.884) and Minor/Major F1 scores.\")\nprint(\"- ‚öñÔ∏è Most balanced performance across all categories (no weak spots).\")\n\n# Visualization\nplt.figure(figsize=(10, 6))\ndf.set_index(\"Model\").plot(kind=\"bar\", y=\"Overall_Score\", legend=False, color=\"gold\")\nplt.title(\"Overall Performance Score (Higher = Better)\")\nplt.ylabel(\"Weighted Score\")\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Sample Python code with multiple intentional errors\nerror_code = \"\"\"\ndef calculate(a, b):\n    return a + b  # No type checking (minor issue)\n    \nresult = calculate(5, '10')  # Type mismatch (major error)\nprint(f\"Result: {result}\")  # Will crash (critical error)\nif False: print(\"Dead code\")  # Unreachable (warning)\n\"\"\"\n\n# Ground truth labels\nground_truth = {\n    'major': [\"Type mismatch in calculate(5, '10')\"],\n    'minor': [\"No type checking in calculate()\"],\n    'critical': [\"TypeError in print(f'Result: {result}')\"],\n    'warning': [\"Unreachable code: if False: print()\"]\n}\n\n# Simulated model outputs (what each model detected)\nmodel_outputs = {\n    'CodeT5': {\n        'major': [\"Type mismatch in calculate(5, '10')\"],\n        'minor': [\"No type checking in calculate()\"],\n        'critical': [\"TypeError in print(f'Result: {result}')\"],\n        'warning': [\"Unreachable code: if False: print()\"]\n    },\n    'GraphCodeBERT': {\n        'major': [\"Type mismatch in calculate(5, '10')\"],\n        'minor': [],  # Missed this\n        'critical': [\"TypeError in print(f'Result: {result}')\"],\n        'warning': []  # Missed this\n    },\n    'CodeBERT': {\n        'major': [\"Type mismatch in calculate(5, '10')\"],\n        'minor': [\"No type checking in calculate()\", \"Extra false positive\"],  # Added incorrect\n        'critical': [\"TypeError in print(f'Result: {result}')\"],\n        'warning': [\"Unreachable code: if False: print()\"]\n    }\n}\n\n# Evaluation function\ndef evaluate_model(true_labels, pred_labels):\n    categories = true_labels.keys()\n    scores = {}\n    \n    for category in categories:\n        # Convert to binary labels (1=found, 0=missed)\n        true_bin = [1 if x in true_labels[category] else 0 for x in true_labels[category]]\n        pred_bin = [1 if x in pred_labels.get(category, []) else 0 for x in true_labels[category]]\n        \n        # Handle empty predictions\n        if not pred_bin:\n            pred_bin = [0]*len(true_bin)\n            \n        scores[f'{category}_precision'] = precision_score(true_bin, pred_bin, zero_division=0)\n        scores[f'{category}_recall'] = recall_score(true_bin, pred_bin, zero_division=0)\n        scores[f'{category}_f1'] = f1_score(true_bin, pred_bin, zero_division=0)\n    \n    # Calculate total score (weighted average)\n    weights = {\n        'major_f1': 0.3,\n        'critical_f1': 0.3,\n        'minor_f1': 0.2,\n        'warning_f1': 0.2\n    }\n    scores['total_score'] = sum(scores[k]*v for k,v in weights.items())\n    \n    return scores\n\n# Evaluate all models\nresults = {}\nfor model, outputs in model_outputs.items():\n    results[model] = evaluate_model(ground_truth, outputs)\n\n# Create comparison DataFrame\ndf = pd.DataFrame(results).T\ndf = df.sort_values('total_score', ascending=False)\n\n# Print results\nprint(\"Error Detection Performance Comparison:\")\nprint(df[['major_f1', 'critical_f1', 'minor_f1', 'warning_f1', 'total_score']])\n\n# Visualize\nax = df['total_score'].plot(kind='bar', title='Total Error Detection Score', color=['gold', 'silver', 'brown'])\nax.set_ylabel('Score (0-1)')\nax.set_xlabel('Model')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n# Final conclusion\nbest_model = df.index[0]\nprint(f\"\\nüèÜ Best Model: {best_model} (Score: {df.loc[best_model, 'total_score']:.3f})\")\nprint(\"Key Strengths:\")\nprint(\"- Perfect detection of major and critical errors\")\nprint(\"- No false positives\")\nprint(\"- Most balanced performance across all error types\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T08:33:33.330036Z","iopub.execute_input":"2025-07-22T08:33:33.330319Z","iopub.status.idle":"2025-07-22T08:33:33.966597Z","shell.execute_reply.started":"2025-07-22T08:33:33.330296Z","shell.execute_reply":"2025-07-22T08:33:33.965318Z"}},"outputs":[{"name":"stdout","text":"Error Detection Performance Comparison:\n               major_f1  critical_f1  minor_f1  warning_f1  total_score\nCodeT5              1.0          1.0       1.0         1.0          1.0\nCodeBERT            1.0          1.0       1.0         1.0          1.0\nGraphCodeBERT       1.0          1.0       0.0         0.0          0.6\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-1f7ed34d66aa>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score (0-1)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"],"ename":"NameError","evalue":"name 'plt' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from transformers import pipeline\n\n# CodeT5\ncodet5_summarizer = pipeline(\"text2text-generation\", model=\"Salesforce/codet5-base-multi-sum\")\ncode = \"def factorial(n): return 1 if n == 0 else n * factorial(n-1)\"\nprint(\"CodeT5 Summary:\", codet5_summarizer(code)[0]['generated_text'])\n\n# UniXcoder\nunixcoder_summarizer = pipeline(\"text-generation\", model=\"microsoft/unixcoder-base\")\nprint(\"UniXcoder Summary:\", unixcoder_summarizer(code)[0]['generated_text'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install transformers datasets scikit-learn torch\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndef evaluate_metrics(y_true, y_pred):\n    return {\n        \"Accuracy\": accuracy_score(y_true, y_pred),\n        \"Precision\": precision_score(y_true, y_pred),\n        \"Recall\": recall_score(y_true, y_pred),\n        \"F1-Score\": f1_score(y_true, y_pred)\n    }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time, psutil\n\ndef benchmark_inference(model, inputs):\n    process = psutil.Process()\n    start_mem = process.memory_info().rss\n    start_time = time.time()\n\n    _ = model.generate(inputs)  # or model.predict if you're classifying\n\n    end_time = time.time()\n    end_mem = process.memory_info().rss\n    return {\n        \"Time (s)\": round(end_time - start_time, 4),\n        \"Memory (MB)\": round((end_mem - start_mem) / 1024**2, 2)\n    }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV to check columns and fix the column access\ndf = pd.read_csv(\"/kaggle/input/optmized/optimized_code_dataset.csv\")\n\n# Display column names to verify correct access\ndf.columns.tolist()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nfor root, dirs, files in os.walk(\"/\"):\n    for file in files:\n        if \"optimized\" in file.lower() and file.endswith(\".csv\"):\n            print(os.path.join(root, file))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(type(model))\nprint(model)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"codebert_model\")\ntokenizer.save_pretrained(\"codebert_model\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    AutoModelForSeq2SeqLM,\n)\nimport torch\nimport os\n\n# Create folders\nos.makedirs(\"saved_models/codebert\", exist_ok=True)\nos.makedirs(\"saved_models/graphcodebert\", exist_ok=True)\nos.makedirs(\"saved_models/codet5\", exist_ok=True)\n\n# Load CodeBERT\ncodebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\ncodebert_model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=2)\ncodebert_model.save_pretrained(\"saved_models/codebert\")\ncodebert_tokenizer.save_pretrained(\"saved_models/codebert\")\n\n# Load GraphCodeBERT\ngraphcodebert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\ngraphcodebert_model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\", num_labels=2)\ngraphcodebert_model.save_pretrained(\"saved_models/graphcodebert\")\ngraphcodebert_tokenizer.save_pretrained(\"saved_models/graphcodebert\")\n\n# Load CodeT5 (seq2seq model)\ncodet5_tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-small\")\ncodet5_model = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/codet5-small\")\ncodet5_model.save_pretrained(\"saved_models/codet5\")\ncodet5_tokenizer.save_pretrained(\"saved_models/codet5\")\n\nprint(\"‚úÖ All models and tokenizers saved successfully.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}